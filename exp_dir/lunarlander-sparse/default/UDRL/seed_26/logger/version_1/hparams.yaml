ACTION_SIZE: 4
STORED_ACTION_SIZE: 1
STORED_STATE_SIZE: 8
action_noise: 1.0
antithetic: false
avg_episode_length: 200
batch_size: 512
continuous_actions: false
desire_advantage: false
desire_cum_rew: true
desire_discounted_rew_to_go: false
desire_horizon: true
desire_mu_minus_std: false
desire_scalings: true
desired_reward: 200
desires_official_order:
- desire_discounted_rew_to_go
- desire_cum_rew
- desire_horizon
- desire_advantage
desires_order:
- desire_cum_rew
- desire_horizon
desires_size: 2
discount_factor: 1.0
display: false
env_name: LunarLander-v2
eval_agent: null
eval_episodes: 10
eval_every: 10
exp_name: cum_rew_new_init_and_hparams
game_dir: exp_dir/lunarlander-sparse/cum_rew_new_init_and_hparams/UDRL/seed_26
gamename: lunarlander-sparse
give_raw_pixels: false
grad_clip_val: 100
hidden_sizes:
- 32
- 128
- 128
- 128
horizon_scale: 0.015
implementation: UDRL
last_few: 25
logdir: exp_dir
lr: 0.0005
max_buffer_size: 100000
max_reward: 320
no_checkpoint: false
no_expo_weighting: true
num_action_repeats: 1
num_grad_steps: 100
num_rand_action_rollouts: 50
num_val_batches: 2
num_workers: 1
over_max_time_limit_penalty: null
print_statements: 0
random_action_epochs: 1
record_n_rollouts_per_epoch: 1
recording_epoch_interval: -1
reload: null
reward_scale: 0.015
seed: 26
sparse: true
td_lambda: 0.95
time_limit: null
training_rollouts_per_worker: 20
trim_shape: null
use_RCP_buffer: false
use_RCP_desire_sampling: false
use_RCP_model: false
use_exp_weight_losses: false
use_lambda_td: false
use_tune: false
use_vae: false
val_func_update_iterval: 5
