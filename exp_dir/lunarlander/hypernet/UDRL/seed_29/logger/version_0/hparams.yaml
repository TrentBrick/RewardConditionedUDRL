ACTION_SIZE: 4
STORED_ACTION_SIZE: 1
STORED_STATE_SIZE: 8
action_noise: 1.0
antithetic: false
avg_episode_length: 200
batch_size: 768
continuous_actions: false
desire_advantage: false
desire_cum_rew: false
desire_discounted_rew_to_go: true
desire_horizon: true
desire_mu_minus_std: false
desire_scalings: true
desired_reward: 200
desires_official_order:
- desire_discounted_rew_to_go
- desire_cum_rew
- desire_horizon
- desire_advantage
discount_factor: 1.0
display: false
env_name: LunarLander-v2
eval_agent: null
eval_episodes: 10
eval_every: 10
exp_name: hypernet
game_dir: exp_dir/lunarlander/hypernet/UDRL/seed_29
gamename: lunarlander
give_raw_pixels: false
grad_clip_val: 100
hidden_sizes:
- 32
- 128
- 128
- 128
horizon_scale: 0.01
implementation: UDRL
last_few: 75
logdir: exp_dir
lr: 0.00035
max_buffer_size: 100000
max_reward: 320
no_checkpoint: false
no_expo_weighting: true
num_action_repeats: 1
num_grad_steps: 100
num_rand_action_rollouts: 50
num_val_batches: 2
num_workers: 1
over_max_time_limit_penalty: null
print_statements: 0
random_action_epochs: 1
record_n_rollouts_per_epoch: 1
recording_epoch_interval: -1
reload: null
reward_scale: 0.025
seed: 29
sparse: false
td_lambda: 0.95
time_limit: null
training_rollouts_per_worker: 20
trim_shape: null
use_RCP_buffer: false
use_RCP_desire_sampling: false
use_RCP_model: false
use_exp_weight_losses: false
use_hyper_model: true
use_lambda_td: false
use_tune: false
use_vae: false
val_func_update_iterval: 5
