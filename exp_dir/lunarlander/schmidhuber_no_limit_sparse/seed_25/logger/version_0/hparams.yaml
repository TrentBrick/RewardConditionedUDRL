ACTION_SIZE: 4
STORED_ACTION_SIZE: 1
STORED_STATE_SIZE: 8
action_noise: 1.0
antithetic: false
avg_episode_length: 200
batch_size: 768
beta_reward_weighting: 1.0
clamp_adv_to_max: false
continuous_actions: false
delta_state: false
desire_advantage: false
desire_cum_rew: true
desire_discounted_rew_to_go: false
desire_horizon: true
desire_mu_minus_std: false
desire_scalings: true
desire_state: false
desired_reward: 200
desires_order:
- desire_cum_rew
- desire_horizon
desires_size: 2
discount_factor: 1.0
display: false
env_name: LunarLander-v2
eval_agent: false
eval_episodes: 10
eval_every: 10
exp_name: schmidhuber_no_limit_sparse
gamename: lunarlander
give_raw_pixels: false
giving_pretrained: false
grad_clip_val: 100
hidden_sizes:
- 32
- 64
- 64
- 64
- 4
horizon_scale: 0.01
last_few: 25
logdir: exp_dir
lr: 0.001
max_buffer_size: 100000
max_loss_weighting: 20
max_reward: 320
no_reload: true
num_action_repeats: 1
num_grad_steps: 100
num_rand_action_rollouts: 10
num_val_batches: 2
num_workers: 1
over_max_time_limit_penalty: null
random_action_epochs: 1
reward_scale: 0.01
seed: 25
sparse: false
state_scale:
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
- 1.0
td_lambda: 0.95
time_limit: null
training_rollouts_per_worker: 20
trim_shape: null
use_Levine_buffer: false
use_Levine_desire_sampling: false
use_Levine_model: false
use_exp_weight_losses: false
use_lambda_td: false
use_vae: false
val_func_update_iterval: 5
