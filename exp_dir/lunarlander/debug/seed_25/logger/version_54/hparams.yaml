ACTION_SIZE: 4
STORED_ACTION_SIZE: 1
STORED_STATE_SIZE: 8
action_noise: 1.0
antithetic: false
avg_episode_length: 200
batch_size: 768
beta_reward_weighting: 1.0
clamp_adv_to_max: false
continuous_actions: false
delta_state: false
desire_advantage: true
desire_cum_rew: true
desire_discounted_rew_to_go: true
desire_horizon: true
desire_mu_minus_std: false
desire_scalings: false
desire_state: true
desired_reward: 200
desires_order:
- desire_discounted_rew_to_go
- desire_cum_rew
- desire_horizon
- desire_state
- desire_advantage
desires_size: 12
discount_factor: 1.0
display: false
env_name: LunarLander-v2
eval_agent: false
eval_episodes: 10
eval_every: 10
exp_name: debug
gamename: lunarlander
give_raw_pixels: false
giving_pretrained: false
grad_clip_val: 100
hidden_sizes:
- 8
- 128
- 128
- 64
last_few: 25
logdir: exp_dir
lr: 0.001
max_buffer_size: 50000
max_loss_weighting: 20
max_reward: 320
multirun: 0
no_reload: true
num_action_repeats: 1
num_grad_steps: 1000
num_rand_action_rollouts: 10
num_val_batches: 2
num_workers: 1
over_max_time_limit_penalty: null
random_action_epochs: 1
seed: 25
sparse: false
td_lambda: 0.95
time_limit: null
training_rollouts_per_worker: 20
trim_shape: null
use_Levine_buffer: false
use_Levine_desire_sampling: false
use_Levine_model: true
use_exp_weight_losses: true
use_lambda_td: true
use_vae: false
val_func_update_iterval: 5
