ACTION_SIZE: 4
STORED_ACTION_SIZE: 1
STORED_STATE_SIZE: 8
action_noise: 1.0
antithetic: false
avg_episode_length: 200
batch_size: 768
beta_reward_weighting: 1.0
clamp_adv_to_max: false
continuous_actions: false
delta_state: false
desire_advantage: false
desire_cum_rew: false
desire_discounted_rew_to_go: false
desire_horizon: false
desire_mu_minus_std: false
desire_next_obs_delta: true
desire_scalings: false
desire_state: false
desired_reward: 200
desires_official_order:
- desire_discounted_rew_to_go
- desire_cum_rew
- desire_horizon
- desire_state
- desire_advantage
- desire_next_obs_delta
desires_order:
- desire_next_obs_delta
desires_size: 1
discount_factor: 1.0
display: false
env_name: LunarLander-v2
eval_agent: false
eval_episodes: 10
eval_every: 10
exp_name: debug
gamename: lunarlander
give_raw_pixels: false
giving_pretrained: false
grad_clip_val: 100
hidden_sizes:
- 8
- 64
- 64
last_few: 25
logdir: exp_dir
lr: 0.001
max_buffer_size: 50000
max_loss_weighting: 20
max_reward: 320
no_reload: true
num_action_repeats: 1
num_grad_steps: 1000
num_rand_action_rollouts: 50
num_val_batches: 2
num_workers: 1
over_max_time_limit_penalty: null
print_statements: 0
random_action_epochs: 1
seed: 25
sparse: false
td_lambda: 0.95
time_limit: null
training_rollouts_per_worker: 20
trim_shape: null
use_Levine_buffer: false
use_Levine_desire_sampling: false
use_Levine_model: true
use_exp_weight_losses: true
use_lambda_td: true
use_vae: false
val_func_update_iterval: 5
